// lex.torth - Lexing functions that parses Tokens from code files
include "std"
include "typing"
include "compiler/defs"
include "compiler/utils"
include "compiler/class/Constant"
include "compiler/class/Func"
include "compiler/class/Match"
include "compiler/class/Memory"
include "compiler/class/Op"
include "compiler/class/Token"
include "compiler/class/Signature"
include "compiler/class/Variable"

// Parse included files from a code string. Return the list of files.
// Params: code_file (STR)
// Return: List[str]
function get_included_files str -> ptr :
  ptr List.init
  peek included_files in List.append

  // Iterate over all of the new included files for this loop iteration
  0 take index in
  while index included_files List.len < do

    // Save the current file name
    index included_files List.nth str.load
    take file_name in

    // Get includes from the current file
    included_files file_name get_included_files_from_file

    // Save the new included files from this iteration
    included_files =
    index 1 + index = // index++
  done
  included_files
end

// Parse included files from a single file. Return the list of files.
// Params: code_file (STR), included_files (List[str])
// Return: included_files (List[str])
function get_included_files_from_file code_file:str included_files:ptr -> ptr :
  // Add compiler's directory and the 'lib' directory to INCLUDE_PATHS
  List.init
  take INCLUDE_PATHS in
  ""      ptr INCLUDE_PATHS List.append
  "lib/"  ptr INCLUDE_PATHS List.append

  // Get the file contents without comments
  INCLUDE_PATHS code_file get_file_name_from_path read_file
  List.init code_file rot get_token_matches_from_code
  False
  0
  take
    index
    parsing_include
    token_matches
  in

  while index token_matches List.len < do
    // Get Nth word from words list
    index token_matches List.nth ptr.load
    Match.get_value
    take token_value in

    // Parse the file name for the include
    if parsing_include do
      token_value take file_name in

      if file_name int NULL == do
        "INCLUDE keyword used without given file name\n"
        "INCLUDE_ERROR" CompilerError
      endif

      // Get the file name that exists using directories in PATH
      INCLUDE_PATHS file_name get_file_name_from_path
      file_name =

      // Do not save file name if it already is in the parsing_include list
      if file_name included_files List.contains_str do
        False parsing_include =
        index 1 + index =
        continue
      endif

      // Save the file name to included_files
      file_name ptr included_files List.append
      False parsing_include =
    endif

    if token_value str.copy str.upper "INCLUDE" streq do
      True parsing_include =
    endif
    index 1 + index = // index++
  done
  included_files
end

// Check every directory in PATH and add .torth extension if needed
// Params: file_name: str, INCLUDE_PATHS: List[str]
// Return: file_with_path: str
function get_file_name_from_path file_name:str INCLUDE_PATHS:ptr -> str :
  // Get the file name without quotes
  if file_name ptr char.load '"' == do
    file_name get_string_inside_quotes
    file_name =
  endif

  if file_name int NULL == do
    "Cannot include file '"
    file_name str.cat
    "'.\n"      str.cat
    "INCLUDE_ERROR" CompilerError
  endif

  if file_name file_exists do
    file_name return
  endif

  // Iterate over INCLUDE PATHS
  // and check if file_name or file_with_extension exists
  0 take include_index in
  while include_index INCLUDE_PATHS List.len < do
    include_index INCLUDE_PATHS List.nth str.load
    take path_dir in

    // Append file_name to path_dir and check if it exists
    path_dir file_name str.cat
    take file_with_path in
    if file_with_path file_exists do
      file_with_path return
    else
      // Check if the file with .torth extension exists
      file_with_path ".torth" str.cat
      file_with_path =
      if file_with_path file_exists do
        file_with_path return
      endif
    endif
    include_index 1 + include_index =
  done

  "File '" file_name       str.cat
  "' cannot be included.\n" str.cat
  "INCLUDE_ERROR" CompilerError ""
end

// Get Token Matches from the code inside included files
// Params:
//    included_files: List[str]
// Return:
//    token_matches: List[Match]
function get_token_matches_from_files included_files:ptr -> ptr :
  List.init
  0
  take index token_matches in

  // Iterate over each included file
  while index included_files List.len < do

    // Read the current file and remove its comments
    index included_files List.nth str.load
    dup read_file
    take code file_name in

    // Parse Token Matches from the current file's code
    token_matches file_name code get_token_matches_from_code
    token_matches =
    index 1 + index = // index++
  done
  token_matches
end

// Get multiline string inside double quotes ""
// Return NULL if there is no string inside quotes
// Params: String which begins with a double quote
// Return: The multiline string between double quotes
function get_string_inside_quotes str -> str :
  str.copy
  take original in

  // Return NULL if the first character is not a double quote
  if original ptr char.load '"' != do
    NULLPTR str return
  endif

  1 while dup original str.len < do
    1 + // index++

    // Return when the other quote is found
    if original over str.char_at '"' == do
      original ptr over ptr+ NULL char swap char.store
      drop
      original 1 str+ return
    endif
  done drop
  NULLPTR str
end

// Transfer comparison and calculations related symbols to their text counterparts
// Params: Token match from code (STR)
// Return: Value for Token (STR)
function get_token_value str -> str :
  str.copy
  take token_match in
  if   token_match "="  streq do
    "ASSIGN" return
  elif token_match "==" streq do
    "EQ" return
  elif token_match ">=" streq do
    "GE" return
  elif token_match ">"  streq do
    "GT" return
  elif token_match "<=" streq do
    "LE" return
  elif token_match "<"  streq do
    "LT" return
  elif token_match "-"  streq do
    "MINUS" return
  elif token_match "*"  streq do
    "MUL" return
  elif token_match "!=" streq do
    "NE" return
  elif token_match "+"  streq do
    "PLUS" return
  endif
  token_match str.escape
end

const single_quote 39 end
function get_token_type token_value:str -> int :
  // Boolean => True
  if
    token_value str.copy str.upper
    dup   "TRUE"  streq
    swap  "FALSE" streq
    ||
  do
    TokenType.BOOL return
  // Character => 'a'
  elif
    token_value str.len 3 ==
    token_value ptr char.load single_quote ==
    token_value 2 str.char_at single_quote ==
    && &&
  do
    TokenType.CHAR return
  // Integer => 1337
  elif
    token_value str.is_numeric
  do
    TokenType.INT return
  // Hexadecimal => 0x1337
  elif
    token_value ptr char.load '0' ==
    token_value 1 str.char_at 'x' ==
    &&
  do
    TokenType.INT return
  // String => "This is string\n"
  elif
    token_value ptr char.load                '"' ==
    token_value dup str.len 1 - str.char_at  '"' ==
    &&
  do
  TokenType.STR return
  // uint8 => u69
  elif
    token_value ptr char.load 'u' ==
    token_value 1 str.char_at char.is_numeric
    &&
  do
    TokenType.UINT8 return
  endif
  TokenType.WORD
end

// Generate Token from Match object
// Params: Match
// Return: Token
function get_token_from_match match:ptr -> ptr :
  match Match.get_value
  match Match.get_location
  take location match_value in

  // Create Token object
  location
  match_value get_token_value
  dup get_token_type
  swap Token.init
end

// Get OpType for Token
// Params: Token
// Return: OpType
function get_op_type token:ptr -> int :
  token Token.type
  take token_type in
  if token_type TokenType.BOOL == do
    OpType.PUSH_BOOL return
  elif token_type TokenType.CHAR == do
    OpType.PUSH_CHAR return
  elif token_type TokenType.INT == do
    OpType.PUSH_INT return
  elif token_type TokenType.STR == do
    OpType.PUSH_STR return
  elif token_type TokenType.UINT8 == do
    OpType.PUSH_UINT8 return
  endif
  OpType.INTRINSIC
end

// Funcs are made of the following parts:
//   1 : Parameter types
//   2 : Return types
//   3 : Body
//  FUNCTION_PART_DELIMITERS: List[str] = ["->", ":", "END"]
function get_function_part_delimiters -> ptr :
  List.init
  take FUNCTION_PART_DELIMITERS in

  "->"        ptr FUNCTION_PART_DELIMITERS List.append
  ":"         ptr FUNCTION_PART_DELIMITERS List.append
  "END"       ptr FUNCTION_PART_DELIMITERS List.append
  FUNCTION_PART_DELIMITERS
end

// Get all words from code to a list
// Params
//    code: str
//    file_name: str
//    token_matches: List[Match]
// Return
//    token_matches: List[Match]
function get_token_matches_from_code
  code:str
  file_name:str
  token_matches:ptr
-> ptr :

  List.init   // newline_indexes
  "" str.copy // String buffer for word
  False       // parsing_string
  False       // parsing_comment
  10          // Line feed character
  0           // index
  take
    index
    LF
    parsing_comment
    parsing_string
    word
    newline_indexes
  in

  // Iterate over every character in code
  while
    code index str.char_at
    peek current_char in
    NULL !=
  do
    // Keep track of the indexes of newline characters (LF)
    if current_char LF == do
      index 1 + ptr newline_indexes List.append
    endif

    // Only a newline ends a comment
    if parsing_comment do
      if current_char LF == do
        False parsing_comment =
      endif
      index 1 + index =
      continue
    endif

    // Only a double quote ends a string
    if parsing_string do
      if current_char '"' == do
        False parsing_string =
      endif
      current_char word str.append
      index 1 + index =
      continue
    endif

    // Double quote starts a string
    if
      current_char '"' ==
      word "'" streq not  // Double quote is not in character definition => '"'
      &&
    do
      True parsing_string =
      current_char word str.append
      index 1 + index =
      continue
    endif

    // Whitespaces separate Tokens
    if
      current_char char.is_whitespace
    do
      // If the word is empty there has been multiple whitespaces in a row
      if word str.len 0 == do
        index 1 + index = // index++
        continue
      endif

      // Check for comments
      if word "//" str.startswith do
        True parsing_comment =
        "" str.copy word =
        index 1 + index =
        continue
      endif

      // Check if the whitespace is inside character definition => ' '
      if word "'" streq do
        current_char word str.append
        index 1 + index =
        continue
      endif

      // Append found Match to token_matches
      newline_indexes index file_name token_matches word append_word_to_token_matches
      "" str.copy word =
    else
      // Append current character to word
      current_char word str.append
    endif
    index 1 + index = // index++
  done

  // Append the last word if the file ended with a word
  if word str.len 0 > do
    newline_indexes index file_name token_matches word append_word_to_token_matches
  endif
  token_matches
end

// Append a word to a List of Matches
function append_word_to_token_matches
  word:str
  token_matches:ptr
  file_name:str
  index:int
  newline_indexes:ptr
:
  // Get Location for the Match
  newline_indexes index word str.len - file_name get_token_location

  // Append the Match to token_matches
  word Match.init
  token_matches List.append
end

// Calculate position for Token based on it's position from the start of the file
// and the indexes of the newline characters found from the file.
// Params: file_name (STR), position (INT), newline_indexes (List[Int])
// Return: Location
function get_token_location
  file_name:str
  position:int
  newline_indexes:ptr
-> ptr :

  position 1 0
  take
    index
    row
    col
  in

  // Get Location for found Token Match
  while index newline_indexes List.len < do
    index newline_indexes List.nth int.load
    take nl_index in

    // Break when the correct row is found
    if nl_index position > do
      break
    endif

    position nl_index - col = // col = position - nl_index
    row 1 + row =             // row++
    index 1 + index =         // index++
  done

  col 1 + row file_name str.copy Location.init
end

// Parse Constants from Token matches
// Params
//    token_matches: List[Match]
// Return
//    constants: List[Constant]
function get_constants token_matches:ptr -> ptr :
  List.init
  ""  str.copy        // constant_name
  dup str.copy        // constant_value
  False               // defining_constant
  0                   // index
  take
    index
    defining_constant
    constant_value
    constant_name
    constants
  in

  while index token_matches List.len < do
    index token_matches List.nth ptr.load
    dup   Match.get_value
    swap  Match.get_location
    take location token_value in

    // Parse Constant only when inside Constant block
    if defining_constant do

      // Parse Constant name
      if constant_name str.len 0 == do
        constants token_value get_constants_name
        constant_name =
        index 1 + index = // index++
        continue
      endif

      // Append the current Constant to constants
      if constant_value str.len 0 == do

        // Parse Constant value
        token_value constant_value =

        // Generate Constant object
        location constant_value constant_name Constant.init
        constants List.append

        // Reset variables
        ""    constant_name   =
        ""    constant_value  =
        False defining_constant =
        index 1 + index = // index++
        continue
      endif
    endif

    if token_value str.copy str.upper "CONST" streq do
      True defining_constant =
    endif
    index 1 + index = // index++
  done
  constants token_matches add_enums_to_constants
end

// Parse and add ENUM block contents to a list of Constants.
// Items inside ENUM blocks are interpreted as running integers starting from 0.
// Params
//    token_matches: List[Match]
//    constants: List[Constant]
// Return
//    constants: List[Constant]
function add_enums_to_constants token_matches:ptr constants:ptr -> ptr :
  get_enum_part_delimiters
  "" str.copy
  NULLPTR
  0
  0
  0
  0
  take
    index
    current_part
    enum_size
    enum_offset
    enum_location
    enum_name
    ENUM_PART_DELIMITERS
  in

  while index token_matches List.len < do

    // Get the current Token Matches value
    index token_matches List.nth ptr.load
    dup  Match.get_value
    swap Match.get_location

    take location token_value in

    if
      token_value str.copy str.upper
      current_part ENUM_PART_DELIMITERS List.nth str.load
      streq
    do
      current_part 1 +
      ENUM_PART_DELIMITERS List.len %
      current_part =

      if token_value str.copy str.upper "END" streq do

        // Constant(enum_name, enum_size*enum_offset, enum_location)
        enum_location
        enum_size enum_offset * itoa
        enum_name
        Constant.init

        // Append the current Enum to the list of Constants
        constants List.append
        index 1 + index =

        // Reset variables
        0 enum_size =
        continue
      endif

    elif current_part 1 == do
      token_value enum_name =
      location enum_location =
      current_part 1 + current_part =

    elif current_part 2 == do
      if token_value str.is_numeric not do
        "'" token_value str.cat
        "' is not a valid offset parameter for ENUM block\n" str.cat
        "VALUE_ERROR" CompilerError
      endif
      token_value atoi enum_offset =
      current_part 1 + current_part =

    elif current_part 3 == do
      "Token '" token_value str.cat
      "' is used in the wrong context when defining '" str.cat
      enum_name str.cat
      "' Enum.\nCheck the syntax of the Enum definition.\n" str.cat
      "VALUE_ERROR" CompilerError

    elif current_part 4 == do
      if constants token_value constant_exists do
        "Constant '" token_value str.cat
        "' is defined multiple times.\n" str.cat
        "Constant names should be unique.\n" str.cat
        "CONST_REDEFINITION" CompilerError
      endif

      // Constant(token_value, enum_size*enum_offset, location)
      location
      enum_size enum_offset * itoa
      token_value
      Constant.init

      // Append the current Enum item to constants
      constants List.append
      enum_size 1 + enum_size =
    endif
    index 1 + index = // index++
  done
  constants
end

// Enums are made of four parts:
//   1 : name
//   2 : size
//   3 : offset
//   4 : items
//  (0 : Not lexing Enum)
//  ENUM_PART_DELIMITERS: List[str] = ["ENUM", "", "", ":", "END"]
function get_enum_part_delimiters -> ptr :
  List.init
  take ENUM_PART_DELIMITERS in
  "ENUM"  ptr ENUM_PART_DELIMITERS List.append
  ""      ptr ENUM_PART_DELIMITERS List.append
  ""      ptr ENUM_PART_DELIMITERS List.append
  ":"     ptr ENUM_PART_DELIMITERS List.append
  "END"   ptr ENUM_PART_DELIMITERS List.append
  ENUM_PART_DELIMITERS
end

// Parse Memories from code
// Params
//    token_matches: List[Match]
//    constants: List[Constant]
// Return
//    memories: List[Memory]
function get_memories token_matches:ptr constants:ptr -> ptr :
  List.init           // memories
  "" str.copy         // memory_name
  NULL                // memory_size
  False               // defining_memory
  0                   // index
  take
    index
    defining_memory
    memory_size
    memory_name
    memories
  in

  while index token_matches List.len < do
    index token_matches List.nth ptr.load
    dup   Match.get_value
    swap  Match.get_location
    take location token_value in

    // Parse Memory only when inside Memory block
    if defining_memory do

      // Parse Memory name
      if memory_name str.len 0 == do
        memories token_value get_memory_name
        memory_name =

        index 1 + index = // index++
        continue
      endif

      // Append the current Memory to memories
      if memory_size 0 == do

        // Use the token_value as memory_size if it is numeric
        if token_value str.is_numeric do
          token_value atoi memory_size =
        else
          // Test if Constant exists
          if constants token_value constant_exists do
            constants token_value get_constant
            Constant.value atoi
            memory_size =
          else
            "The memory size should be an integer. Got: "
            token_value str.cat
            "VALUE_ERROR" CompilerError
          endif
        endif

        // Generate Memory object
        location memory_size memory_name str.copy Memory.init
        memories List.append

        // Reset variables
        ""    memory_name =
        NULL  memory_size =
        False defining_memory =
        index 1 + index = // index++
        continue
      endif
    endif

    if token_value str.copy str.upper "MEMORY" streq do
      True defining_memory =
    endif
    index 1 + index = // index++
  done
  memories
end

// Check for redefinition of a Constant object
// Params
//    token_value: str
//    constants: List[Constant]
// Return
//    memory_name: str
function get_constants_name token_value:str constants:ptr -> str :
  // Overwriting another Memory is not allowed
  if token_value constants List.contains_str do
    "Constant '" token_value str.cat
    "' already exists. Constant name should be unique.\n" str.cat
    "CONSTANT_REDEFINITION" CompilerError
  endif
  token_value
end

// Check for redefinition of a Memory object
// Params
//    token_value: str
//    memories: List[Memory]
// Return
//    memory_name: str
function get_memory_name token_value:str memories:ptr -> str :
  // Overwriting another Memory is not allowed
  if token_value memories List.contains_str do
    "Memory '" token_value str.cat
    "' already exists. Memory name should be unique.\n" str.cat
    "MEMORY_REDEFINITION" CompilerError
  endif
  token_value
end

// Parse Funcs from list of token Matches
// Params
//    token_matches:  List[Match]
//    constants:      List[Constant]
//    memories:       List[Memory]
// Return
//    functions: List[Func]
function get_functions
  token_matches:ptr
  constants:ptr
  memories:ptr
-> ptr :
  List.init // List[Func]
  0
  take index functions in
  while index token_matches List.len < do
    // Get current word
    index token_matches List.nth ptr.load
    get_token_from_match Token.value str.copy str.upper
    take token_upper in
    
    if token_upper "FUNCTION" streq do
      index 1 + index =
      "" memories constants index token_matches parse_function
      functions List.append
    endif
    index 1 + index =
  done

  // Verify that the program has MAIN function (case-insensitive)
  if functions main_function_in_function_list not do
    "The program does not have an entry point.\n"
    "Please add Main function (case-insensitive)." str.cat
    "MISSING_MAIN_FUNCTION" CompilerError
  endif
  functions
end

// Parse Func from list of token Matches
// Params
//    token_matches:  List[Match]
//    token_index:    int
//    constants:      List[Constant]
//    memories:       List[Memory]
// Return Func
function parse_function
  token_matches:ptr
  token_index:int
  constants:ptr
  memories:ptr
  class_name:str
-> ptr :
  // Initialize variables
  get_function_part_delimiters  // FUNCTION_PART_DELIMITERS
  List.init                     // List[Token]
  0                             // current_part
  List.init                     // return_types
  List.init                     // param_types
  List.init                     // variables
  take
    variables
    param_types
    return_types
    current_part
    tokens
    FUNCTION_PART_DELIMITERS
  in

  if token_index token_matches List.len >= do
    "Program cannot end with '"
    token_matches List.last ptr.load
    Match.get_value str.cat
    "' token"       str.cat
    "SYNTAX_ERROR" CompilerError
  endif

  // Set Func.name
  token_index token_matches List.nth ptr.load Match.get_value
  take function_name in
  token_index 1 + token_index =

  // Class methods are called as <class_name>.<method>
  // Example: Dog.bark
  if class_name "" streq not do
    class_name "."  str.cat
    function_name   str.cat
    function_name =
  endif

  while token_index token_matches List.len < do
    // Get current word
    token_index token_matches List.nth ptr.load
    get_token_from_match
    dup Token.value
    take token_value token in

    if
      token_value str.copy str.upper
      current_part FUNCTION_PART_DELIMITERS List.nth str.load
      streq
    do
      current_part 1 +
      current_part =

      // Append Func and reset variables when function is fully lexed
      if token_value str.copy str.upper "END" streq do

        // Append 0 token as the exit code for MAIN function
        if function_name str.copy str.upper "MAIN" streq do
          token Token.location
          TokenType.INT "0" Token.init
          tokens List.append
        endif

        // Do not allow empty functions
        if tokens List.len 0 == do
          token
          "Func '" function_name                        str.cat
          "' does not have any tokens\n"                str.cat
          "Creation of empty functions is not allowed"  str.cat
          "EMPTY_FUNCTION" CompilerErrorWithToken
        endif

        // return Func(function_name, signature, tokens, variables)
        variables
        tokens
        return_types param_types Signature.init
        function_name Func.init
        return
      endif

    elif current_part 0 == do
      // Enable defining functions that do not return anything without the -> token
      // FUNCTION <name> <param_types> : <function_body> END
      if token_value ":" streq do
        current_part 2 + current_part =
        token_index 1 + token_index =
        token_value str.delete
        continue
      endif

      // Split token by colon to name and TokenType
      // Example => parameter_name:int
      ":" token_value str.find
      take param_colon in

      // Parse parameter's TokenType
      token_value param_colon 1 + str+
      Signature.type_map
      take param_type in
      param_type ptr param_types List.append

      // Handle named parameters
      if param_colon -1 != do
        // Empty param_name
        if param_colon 0 == do
          token
          "Func '" function_name                      str.cat
          "' has parameter '"                         str.cat
          token_value                                 str.cat
          "' which has a colon but the name is empty" str.cat
          "SYNTAX_ERROR" CompilerErrorWithToken
        endif

        // Parse parameter's name
        token_value str.copy
        dup param_colon str+ str.empty
        take param_name in

        // Append parameter to Func's Tokens
        param_name str.copy token Token->value
        TokenType.WORD      token Token->type
        VarType.TAKE        token Token->vartype
        token tokens List.append

        // Add parameter to the list of Variables
        memories variables function_name token add_variable_to_list
      endif

    elif current_part 1 == do
      // Append word to return_types if valid TokenType
      token_value Signature.type_map ptr
      return_types List.append

    elif current_part 2 == do
      // Use Constant's value if a Constant exists named as the Token's value
      if constants token_value constant_exists do

        // Find the constant from list of Constants
        0 take constant_index in
        while constant_index constants List.len < do
          constant_index constants List.nth ptr.load
          take constant in

          if constant Constant.name token_value streq do
            constant Constant.value str.copy
            token Token->value
            TokenType.INT token Token->type
            break
          endif
          constant_index 1 + constant_index =
        done
      endif

      // Append the current Token to the list of tokens
      token tokens List.append

    else
      "Unknown error - Function parsing failed"
      "ASSERTION_ERROR" CompilerError
    endif
    token_index 1 + token_index =
  done

  // Could not parse Func
  token
  "Could not parse function '"
  function_name               str.cat
  "'\nUnexpected end of file" str.cat
  "SYNTAX_ERROR" CompilerErrorWithToken
  NULLPTR
end

// Parse Classes from code
// Params
//    token_matches:  List[Match]
//    functions:      List[Func]
//    constants:      List[Constant]
//    memories:       List[Memory]
// Return
//    functions: List[Func]
function parse_classes
  token_matches:ptr
  functions:ptr
  constants:ptr
  memories:ptr
:
  0 take index in
  while index token_matches List.len < do
    // Get current word
    index token_matches List.nth ptr.load
    get_token_from_match Token.value str.copy str.upper
    take token_upper in

    if token_upper str.copy str.upper "CLASS" streq do
      index 1 + index =
      memories constants functions index token_matches parse_class
    endif
    index 1 + index =
  done

  // Parse the variables for each function
  memories functions parse_variables_for_functions
end

function parse_class
  token_matches:ptr
  token_index:int
  functions:ptr
  constants:ptr
  memories:ptr
:
  if token_index token_matches List.len >= do
    "Class cannot end with '"
    token_matches List.last ptr.load
    Match.get_value str.cat
    "' token"       str.cat
    "SYNTAX_ERROR" CompilerError
  endif

  // Get Class name
  token_index token_matches List.nth ptr.load Match.get_value
  take class_name in
  token_index 1 + token_index =

  0 take attribute_count in
  while token_index token_matches List.len < do
    // Get current word
    token_index token_matches List.nth ptr.load
    get_token_from_match
    dup Token.value
    take token_value token in

    if token_value str.copy str.upper "METHOD" streq do
      // Parse all methods
      token_index 1 + token_index =
      class_name memories constants token_index token_matches parse_function
      take class_method in

      // Add method to list of functions
      class_method functions List.append

      // Go over the method's END keyword
      while token_index token_matches List.len < do
        token_index token_matches List.nth ptr.load
        if Token.value str.copy str.upper "END" streq do
          break
        endif
        token_index 1 + token_index =
      done

    // Class ends with ENDCLASS
    elif token_value str.copy str.upper "ENDCLASS" streq do
      // Add function called <class_name>.size
      token attribute_count class_name get_object_size_function
      functions List.append
      return

    // Parse class attributes
    else
      functions token attribute_count class_name parse_class_attribute
      attribute_count 1 + attribute_count =
    endif
    token_index 1 + token_index =
  done

  // Could not parse class
  token
  "Could not parse class '"
  class_name                  str.cat
  "'\nUnexpected end of file" str.cat
  "SYNTAX_ERROR" CompilerErrorWithToken
end

function parse_class_attribute
  class_name:str
  attribute_count:int
  token:ptr
  functions:ptr
:
  // Split token by colon to attribute's name and TokenType
  // Example => attribute_name:int
  token Token.value
  ":" over str.find
  take attribute_colon token_value in

  // Attribute should have a colon to separate its name and TokenType
  if
    attribute_colon -1 ==
    attribute_colon 0  ==
    ||
  do
    token
    "Invalid instance attribute '" token_value                            str.cat
    "'.\nThe attribute have a colon to separate its name and TokenType\n" str.cat
    "Example => attribute_name:int"                                       str.cat
    "SYNTAX_ERROR" CompilerErrorWithToken
  endif

  // Parse attribute's TokenType
  token_value attribute_colon 1 + str+
  Signature.type_map
  take attribute_type in

  // Parse attribute's name
  token_value str.copy
  dup attribute_colon str+ str.empty
  take attribute_name in

  // Calculate attributes byte offset from object base pointer
  attribute_count int.size *
  take attribute_offset in

  // Add getter to Func list
  True token attribute_offset attribute_type attribute_name class_name
  generate_attribution_functions functions List.append

  // Add setter to Func list
  False token attribute_offset attribute_type attribute_name class_name
  generate_attribution_functions functions List.append
end

function get_object_size_function
  class_name:str
  attribute_count:int
  endclass_token:ptr
-> ptr :
  class_name ".size" str.cat  // function_name
  List.init                   // tokens
  List.init                   // return_types
  attribute_count ptr.size *  // class_size
  take
    class_size
    return_types
    tokens
    function_name
  in

  // Insert integer Token containing class_size to Token list
  endclass_token Token.location TokenType.INT class_size itoa Token.init
  tokens List.append

  // Signature: None -> INT
  TokenType.INT ptr return_types List.append
  return_types List.init Signature.init
  take signature in

  List.init tokens signature function_name Func.init
end

function generate_attribution_functions
  class_name:str
  attribute_name:str
  attribute_type:int
  attribute_offset:int
  attribute_token:ptr
  is_getter:bool // Getter => True, Setter => False
-> ptr :
  // Func.name => Class.attribute OR Class->attribute
  class_name
  if is_getter
  do   "."
  else "->"
  endif           str.cat
  attribute_name  str.cat
  take function_name in

  // Func.Signature
  List.init
  List.init
  take param_types return_types in
  TokenType.PTR  ptr param_types List.append
  attribute_type ptr
  // Insert attribute_type to either parameter or return types
  // depending on if the function is getter or setter
  if is_getter
  do   return_types
  else param_types
  endif List.append
  return_types param_types Signature.init
  take signature in

  // Func.tokens
  is_getter attribute_token attribute_offset attribute_type attribute_name class_name get_attribute_function_tokens
  take tokens in

  // Create Func and append it to list of Funcs
  List.init tokens signature function_name Func.init
end

function get_attribute_function_tokens
  class_name:str
  attribute_name:str
  attribute_type:int
  attribute_offset:int
  attribute_token:ptr
  is_getter:bool // Getter => True, Setter => False
-> ptr :
  attribute_offset itoa
  " swap int + ptr " str.cat
  if is_getter
  do   "LOAD_QWORD "  str.cat attribute_type TokenType.repr str.cat
  else "STORE_QWORD " str.cat
  endif
  List.init
  attribute_token Token.location
  dup Location.get_file
  take
    file_name
    location
    token_matches
    code
  in

  token_matches file_name code get_token_matches_from_code
  List.init
  0
  take
    index
    tokens
    token_matches
  in
  while index token_matches List.len < do
    index token_matches List.nth ptr.load
    get_token_from_match
    take token in

    // Fix the Location to correspond with the attribute's Token
    location token Token->location
    token tokens List.append
    index 1 + index =
  done
  tokens
end

// Parse Variables for Funcs
// Params: List[Func], List[Memory]
function parse_variables_for_functions functions:ptr memories:ptr :
  functions List.len
  0
  take index functions.len in

  // Parse Variables for each Func
  while index functions.len < do
    index functions List.nth ptr.load
    memories swap parse_function_variables
    index 1 + index = // index++
  done
end

// Parse Variables in Func
// Params: Func, List[Memory]
// Return: None
function parse_function_variables func:ptr memories:ptr :
  func Func.tokens
  func Func.variables
  False
  "PEEK"
  0
  take
    index
    bind_variant
    parsing_variables
    variables
    tokens
  in

  while index tokens List.len < do
    index tokens List.nth ptr.load
    dup Token.value
    take
      token_value
      token
    in

    // Variable parsing block is started with PEEK or TAKE keyword
    if
      token_value str.copy str.upper
      dup  "PEEK" streq
      swap "TAKE" streq
      ||
    do
      True parsing_variables =
      token_value str.copy str.upper bind_variant =

    // IN keyword closes the Variable parsing block
    elif token_value str.copy str.upper "IN" streq do
      False parsing_variables =

    // Every word is considered as a Variable in the block between PEEK/TAKE and IN
    elif parsing_variables do
      if bind_variant "PEEK" streq do
        VarType.PEEK token Token->vartype
      elif bind_variant "TAKE" streq do
        VarType.TAKE token Token->vartype
      else
        token
        "Unknown VarType '" bind_variant str.cat "'\n" str.cat
        "VALUE_ERROR" CompilerErrorWithToken
      endif

      // Add Variable to Func's list of Variables
      memories variables func Func.name token add_variable_to_list

    // Token is a function parameter
    elif token Token.vartype 0 != do
      index 1 + index =
      continue

    // Token is an already defined Variable
    elif token_value variables List.contains_variable do
      VarType.PUSH token Token->vartype
    endif
    index 1 + index =
  done
end

// Add variable to Func's variable list
// Params
//    token: Token
//    function_name: str
//    variables: List[Variable]
//    memories: List[Memory]
function add_variable_to_list
  token:ptr
  function_name:str
  variables:ptr
  memories:ptr
:

  token Token.type
  token Token.value
  take token_value token_type in

  // Append the variable to the list of function's variables
  token_type token_value Variable.init
  variables List.append

  // Add the Variable to the list of memories
  function_name "_" str.cat
  token_value       str.cat
  take memory_name in
  if memories memory_name memory_exists not do
    token Token.location
    ptr.size // Memory.size
    memory_name
    Memory.init
    memories List.append
  endif
end

// Verify if MAIN function is defined (case-insensitive)
// Params
//    functions:ptr
// Return bool
function main_function_in_function_list functions:ptr -> bool :
  functions List.len
  0
  take index functions.len in

  // Iterate over Func List
  while index functions.len < do
    index functions List.nth ptr.load
    Func.name str.copy str.upper
    take function_name in

    // Return True if MAIN function is found
    if function_name "MAIN" streq do
      True return
    endif
    index 1 + index =
  done
  False
end
