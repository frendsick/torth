// lex.torth - Lexing functions that parses Tokens from code files
include "std"
include "typing"
include "compiler/defs"
include "compiler/utils"
include "compiler/class/Constant"
include "compiler/class/Func"
include "compiler/class/Op"
include "compiler/class/Token"
include "compiler/class/Signature"
include "compiler/class/Variable"

// Parse included files from a code string. Return the list of files.
function get_included_files str -> List :
  cast(ptr) List.init
  peek included_files in List.append

  // Iterate over all of the new included files for this loop iteration
  0 take index in
  while index included_files List.len < do

    // Save the current file name
    index included_files List.nth str.load
    take file_name in

    // Get includes from the current file
    included_files file_name get_included_files_from_file

    // Save the new included files from this iteration
    included_files =
    index 1 + index = // index++
  done
  included_files
end

// Parse included files from a single file. Return the list of files.
// Params: code_file (STR), included_files (List[str])
// Return: included_files (List[str])
function get_included_files_from_file code_file:str included_files:List -> List :
  // Add compiler's directory and the 'lib' directory to INCLUDE_PATHS
  List.init
  take INCLUDE_PATHS in
  ""      cast(ptr) INCLUDE_PATHS List.append
  "lib/"  cast(ptr) INCLUDE_PATHS List.append

  // Get the file contents without comments
  INCLUDE_PATHS code_file get_file_name_from_path read_file
  List.init cast(List[Token]) code_file rot get_tokens_from_code
  False
  0
  take
    index
    parsing_include
    tokens
  in

  while index tokens cast(List) List.len < do
    // Get Nth Token
    index tokens cast(List) List.nth ptr.load Token.value
    take token_value in

    // Parse the file name for the include
    if parsing_include do
      token_value take file_name in

      if file_name cast(int) NULL == do
        "INCLUDE keyword used without given file name\n"
        "INCLUDE_ERROR" CompilerError
      endif

      // Get the file name that exists using directories in PATH
      INCLUDE_PATHS file_name get_file_name_from_path
      file_name =

      // Do not save file name if it already is in the parsing_include list
      if file_name included_files List.contains_str do
        False parsing_include =
        index 1 + index =
        continue
      endif

      // Save the file name to included_files
      file_name cast(ptr) included_files List.append
      False parsing_include =
    endif

    if token_value str.copy str.upper "INCLUDE" streq do
      True parsing_include =
    endif
    index 1 + index = // index++
  done
  included_files
end

// Check every directory in PATH and add .torth extension if needed
// Params: file_name: str, INCLUDE_PATHS: List[str]
// Return: file_with_path: str
function get_file_name_from_path file_name:str INCLUDE_PATHS:List -> str :
  // Get the file name without quotes
  if file_name cast(ptr) char.load '"' == do
    file_name get_string_inside_quotes
    file_name =
  endif

  if file_name cast(int) NULL == do
    "Cannot include file '"
    file_name str.cat
    "'.\n"      str.cat
    "INCLUDE_ERROR" CompilerError
  endif

  if file_name file_exists do
    file_name return
  endif

  // Iterate over INCLUDE PATHS
  // and check if file_name or file_with_extension exists
  0 take include_index in
  while include_index INCLUDE_PATHS List.len < do
    include_index INCLUDE_PATHS List.nth str.load
    take path_dir in

    // Append file_name to path_dir and check if it exists
    path_dir file_name str.cat
    take file_with_path in
    if file_with_path file_exists do
      file_with_path return
    else
      // Check if the file with .torth extension exists
      file_with_path ".torth" str.cat
      file_with_path =
      if file_with_path file_exists do
        file_with_path return
      endif
    endif
    include_index 1 + include_index =
  done

  "File '" file_name       str.cat
  "' cannot be included.\n" str.cat
  "INCLUDE_ERROR" CompilerError ""
end

// Get Tokens from the code inside included files
function get_tokens_from_files included_files:List -> List[Token] :
  List.init cast(List[Token])
  0
  take index tokens in

  // Iterate over each included file
  while index included_files List.len < do

    // Read the current file and remove its comments
    index included_files List.nth str.load
    dup read_file
    take code file_name in

    // Parse Tokens from the current file's code
    tokens file_name code get_tokens_from_code
    tokens =
    index 1 + index = // index++
  done
  tokens
end

// Get multiline string inside double quotes ""
// Return NULL if there is no string inside quotes
// Params: String which begins with a double quote
// Return: The multiline string between double quotes
function get_string_inside_quotes str -> str :
  str.copy
  take original in

  // Return NULL if the first character is not a double quote
  if original cast(ptr) char.load '"' != do
    NULLPTR cast(str) return
  endif

  1 while dup original str.len < do
    1 + // index++

    // Return when the other quote is found
    if dup original str.char_at '"' == do
      original cast(ptr) over ptr+ NULL cast(char) swap char.store
      drop
      original 1 str+ return
    endif
  done drop
  NULLPTR cast(str)
end

// Transfer comparison and calculations related symbols to their text counterparts
// Params: Token value from code (STR)
// Return: Value for Token (STR)
function get_token_value token_value:str -> str :
  if   token_value "="  streq do
    "ASSIGN" return
  elif token_value "/" streq do
    "DIV" return
  elif token_value "==" streq do
    "EQ" return
  elif token_value ">=" streq do
    "GE" return
  elif token_value ">"  streq do
    "GT" return
  elif token_value "<=" streq do
    "LE" return
  elif token_value "<"  streq do
    "LT" return
  elif token_value "-"  streq do
    "MINUS" return
  elif token_value "%"  streq do
    "MOD" return
  elif token_value "*"  streq do
    "MUL" return
  elif token_value "!=" streq do
    "NE" return
  elif token_value "+"  streq do
    "PLUS" return
  endif
  token_value str.escape
end

const single_quote 39 end
function get_token_type token_value:str -> str :
  // Boolean => True
  if
    token_value str.copy str.upper
    dup   "TRUE"  streq
    swap  "FALSE" streq
    ||
  do
    "bool" return
  // Character => 'a'
  elif
    token_value str.len 3 ==
    token_value cast(ptr) char.load single_quote ==
    2 token_value str.char_at single_quote ==
    && &&
  do
   "char" return
  // Integer => 1337
  elif
    token_value str.is_numeric
  do
    "int" return
  // Hexadecimal => 0x1337
  elif
    token_value cast(ptr) char.load '0' ==
    1 token_value str.char_at 'x' ==
    &&
  do
    "int" return
  // String => "This is string\n"
  elif
    token_value cast(ptr) char.load                 '"' ==
    token_value str.len 1 - token_value str.char_at '"' ==
    &&
  do
  "str" return
  endif
  "word"
end

// Funcs are made of the following parts:
//   1 : Parameter types
//   2 : Return types
//   3 : Body
//  FUNCTION_PART_DELIMITERS: List[str] = ["->", ":", "END"]
function get_function_part_delimiters -> List :
  List.init
  take FUNCTION_PART_DELIMITERS in

  "->"        cast(ptr) FUNCTION_PART_DELIMITERS List.append
  ":"         cast(ptr) FUNCTION_PART_DELIMITERS List.append
  "END"       cast(ptr) FUNCTION_PART_DELIMITERS List.append
  FUNCTION_PART_DELIMITERS
end

// Get all words from code to a list
// Params
//    code: str
//    file_name: str
//    tokens: List[Token]
// Return
//    tokens: List[Token]
function get_tokens_from_code
  code:str
  file_name:str
  tokens:List[Token]
-> List[Token] :

  List.init   // newline_indexes
  "" str.copy // String buffer for word
  False       // parsing_string
  False       // parsing_comment
  10          // Line feed character
  0           // index
  take
    index
    LF
    parsing_comment
    parsing_string
    word
    newline_indexes
  in

  // Iterate over every character in code
  while
    index code str.char_at
    peek current_char in
    NULL !=
  do
    // Keep track of the indexes of newline characters (LF)
    if current_char LF == do
      index 1 + cast(ptr) newline_indexes List.append
    endif

    // Only a newline ends a comment
    if parsing_comment do
      if current_char LF == do
        False parsing_comment =
      endif
      index 1 + index =
      continue
    endif

    // Only a double quote ends a string
    if parsing_string do
      if current_char '"' == do
        False parsing_string =
      endif
      current_char word str.append
      index 1 + index =
      continue
    endif

    // Double quote starts a string
    if
      current_char '"' ==
      word "'" streq not  // Double quote is not in character definition => '"'
      &&
    do
      True parsing_string =
      current_char word str.append
      index 1 + index =
      continue
    endif

    // Whitespaces separate Tokens
    if
      current_char char.is_whitespace
    do
      // If the word is empty there has been multiple whitespaces in a row
      if word str.len 0 == do
        index 1 + index = // index++
        continue
      endif

      // Check for comments
      if word "//" str.startswith do
        True parsing_comment =
        "" str.copy word =
        index 1 + index =
        continue
      endif

      // Check if the whitespace is inside character definition => ' '
      if word "'" streq do
        current_char word str.append
        index 1 + index =
        continue
      endif

      // Append found Token to list
      newline_indexes index file_name tokens word append_word_to_tokens
      "" str.copy word =
    else
      // Append current character to word
      current_char word str.append
    endif
    index 1 + index = // index++
  done

  // Append the last word if the file ended with a word
  if word str.len 0 > do
    newline_indexes index file_name tokens word append_word_to_tokens
  endif
  tokens
end

// Append a word to a List of Tokens
function append_word_to_tokens
  word:str
  tokens:List[Token]
  file_name:str
  index:int
  newline_indexes:List
:
  // Token.Location
  newline_indexes index word str.len - file_name get_token_location
  // Token.name
  word get_token_value
  // Token.type
  dup get_token_type
  take type value location in

  // Append the Token to list
  location type value Token.init
  tokens cast(List) List.append
end

// Calculate position for Token based on it's position from the start of the file
// and the indexes of the newline characters found from the file.
// Params: file_name (STR), position (INT), newline_indexes (List[Int])
// Return: Location
function get_token_location
  file_name:str
  position:int
  newline_indexes:List
-> Location :

  position 1 0
  take
    index
    row
    col
  in

  // Get Location for found Token
  while index newline_indexes List.len < do
    index newline_indexes List.nth int.load
    take nl_index in

    // Break when the correct row is found
    if nl_index position > do
      break
    endif

    position nl_index - col = // col = position - nl_index
    row 1 + row =             // row++
    index 1 + index =         // index++
  done

  col 1 + row file_name str.copy Location.init
end

// Parse Constants from Tokens
// Params
//    tokens: List[Token]
// Return
//    constants: List[Constant]
function get_constants tokens:List[Token] -> List[Constant] :
  List.init cast(List[Constant])
  ""  str.copy        // constant_name
  dup str.copy        // constant_value
  False               // defining_constant
  0                   // index
  take
    index
    defining_constant
    constant_value
    constant_name
    constants
  in

  while index tokens cast(List) List.len < do
    index tokens cast(List) List.nth ptr.load
    dup   Token.value
    swap  Token.location
    take location token_value in

    // Parse Constant only when inside Constant block
    if defining_constant do

      // Parse Constant name
      if constant_name str.len 0 == do
        token_value constants get_constants_name
        constant_name =
        index 1 + index = // index++
        continue
      endif

      // Append the current Constant to constants
      if constant_value str.len 0 == do

        // Parse Constant value
        token_value constant_value =

        // Generate Constant object
        location constant_value constant_name Constant.init
        constants cast(List) List.append

        // Reset variables
        ""    constant_name   =
        ""    constant_value  =
        False defining_constant =
        index 1 + index = // index++
        continue
      endif
    endif

    if token_value str.copy str.upper "CONST" streq do
      True defining_constant =
    endif
    index 1 + index = // index++
  done

  if tokens cast(List) List.len 0 > do
    constants tokens add_enums_to_constants
  endif
  constants
end

// Parse and add ENUM block contents to a list of Constants.
// Items inside ENUM blocks are interpreted as running integers starting from 0.
// Params
//    tokens: List[Token]
//    constants: List[Constant]
// Return
//    constants: List[Constant]
function add_enums_to_constants tokens:List[Token] constants:List[Constant] :
  get_enum_part_delimiters
  "" str.copy
  tokens cast(List) List.first Token.load Token.location
  0
  0
  0
  0
  take
    index
    current_part
    enum_size
    enum_offset
    enum_location
    enum_name
    ENUM_PART_DELIMITERS
  in

  while index tokens cast(List) List.len < do

    // Get the current Token's value
    index tokens cast(List) List.nth ptr.load
    dup  Token.value
    swap Token.location

    take location token_value in

    if
      token_value str.copy str.upper
      current_part ENUM_PART_DELIMITERS List.nth str.load
      streq
    do
      current_part 1 +
      ENUM_PART_DELIMITERS List.len %
      current_part =

      if token_value str.copy str.upper "END" streq do

        // Constant(enum_name, enum_size*enum_offset, enum_location)
        enum_location
        enum_size enum_offset * itoa
        enum_name
        Constant.init

        // Append the current Enum to the list of Constants
        constants cast(List) List.append
        index 1 + index =

        // Reset variables
        0 enum_size =
        continue
      endif

    elif current_part 1 == do
      token_value enum_name =
      location enum_location =
      current_part 1 + current_part =

    elif current_part 2 == do
      if token_value str.is_numeric not do
        "'" token_value str.cat
        "' is not a valid offset parameter for ENUM block\n" str.cat
        "VALUE_ERROR" CompilerError
      endif
      token_value atoi enum_offset =
      current_part 1 + current_part =

    elif current_part 3 == do
      "Token '" token_value str.cat
      "' is used in the wrong context when defining '" str.cat
      enum_name str.cat
      "' Enum.\nCheck the syntax of the Enum definition.\n" str.cat
      "VALUE_ERROR" CompilerError

    elif current_part 4 == do
      if constants token_value constant_exists do
        "Constant '" token_value str.cat
        "' is defined multiple times.\n" str.cat
        "Constant names should be unique.\n" str.cat
        "CONST_REDEFINITION" CompilerError
      endif

      // Constant(token_value, enum_size*enum_offset, location)
      location
      enum_size enum_offset * itoa
      token_value
      Constant.init

      // Append the current Enum item to constants
      constants cast(List) List.append
      enum_size 1 + enum_size =
    endif
    index 1 + index = // index++
  done
end

// Enums are made of four parts:
//   1 : name
//   2 : size
//   3 : offset
//   4 : items
//  (0 : Not lexing Enum)
//  ENUM_PART_DELIMITERS: List[str] = ["ENUM", "", "", ":", "END"]
function get_enum_part_delimiters -> List :
  List.init
  take ENUM_PART_DELIMITERS in
  "ENUM"  cast(ptr) ENUM_PART_DELIMITERS List.append
  ""      cast(ptr) ENUM_PART_DELIMITERS List.append
  ""      cast(ptr) ENUM_PART_DELIMITERS List.append
  ":"     cast(ptr) ENUM_PART_DELIMITERS List.append
  "END"   cast(ptr) ENUM_PART_DELIMITERS List.append
  ENUM_PART_DELIMITERS
end

// Check for redefinition of a Constant object
function get_constants_name constants:List[Constant] token_value:str -> str :
  // Overwriting another Constant is not allowed
  if token_value constants cast(List) List.contains_str do
    "Constant '" token_value str.cat
    "' already exists. Constant name should be unique.\n" str.cat
    "CONSTANT_REDEFINITION" CompilerError
  endif
  token_value
end

// Parse Functions from list of Tokens
// Params
//    tokens:     List[Token]
//    constants:  List[Constant]
// Return
//    functions: List[Func]
function get_functions
  tokens:List[Token]
  constants:List[Constant]
-> List[Func] :
  List.init cast(List[Func])
  0
  take index functions in
  while index tokens cast(List) List.len < do
    // Get current word
    index tokens cast(List) List.nth ptr.load
    Token.value str.copy str.upper
    take token_upper in
    
    if token_upper "FUNCTION" streq do
      index 1 + index =
      "" constants index tokens parse_function
      functions cast(List) List.append
    endif
    index 1 + index =
  done

  // Verify that the program has a 'main' function
  if functions main_function_in_function_list not do
    "The program does not have an entry point.\n"
    "Please add 'main' function." str.cat
    "MISSING_MAIN_FUNCTION" CompilerError
  endif
  functions
end

// Parse Function from list of Tokens
// Params
//    tokens:       List[Token]
//    token_index:  int
//    constants:    List[Constant]
// Return Func
function parse_function
  tokens:List[Token]
  token_index:int
  constants:List[Constant]
  class_name:str
-> Func :
  // Initialize variables
  get_function_part_delimiters    // FUNCTION_PART_DELIMITERS
  List.init cast(List[Token])     // function_tokens
  0                               // current_part
  List.init                       // return_types
  List.init                       // param_types
  List.init cast(List[Variable])  // variables
  take
    variables
    param_types
    return_types
    current_part
    function_tokens
    FUNCTION_PART_DELIMITERS
  in

  if token_index tokens cast(List) List.len >= do
    "Program cannot end with '"
    tokens cast(List) List.last Token.load
    Token.value str.cat
    "' token"   str.cat
    "SYNTAX_ERROR" CompilerError
  endif

  // Set Func.name
  token_index tokens cast(List) List.nth ptr.load Token.value
  take function_name in
  token_index 1 + token_index =

  // Class methods are called as <class_name>.<method>
  // Example: Dog.bark
  if class_name "" streq not do
    class_name "."  str.cat
    function_name   str.cat
    function_name =
  endif

  while token_index tokens cast(List) List.len < do
    // Get current Token
    token_index tokens cast(List) List.nth Token.load
    dup Token.value
    take token_value token in

    if
      token_value str.copy str.upper
      current_part FUNCTION_PART_DELIMITERS List.nth str.load
      streq
    do
      current_part 1 +
      current_part =

      // Append Func and reset variables when function is fully lexed
      if token_value str.copy str.upper "END" streq do

        // Append 0 token as the exit code for MAIN function
        if function_name str.copy str.upper "MAIN" streq do
          token Token.location
          "int" "0" Token.init
          function_tokens cast(List) List.append
        endif

        // return Func(function_name, signature, function_tokens, variables)
        variables
        function_tokens
        return_types param_types Signature.init
        function_name Func.init
        take func in

        // Set MAIN function as used
        if func Func.name str.copy str.upper "MAIN" streq do
            TRUE func Func->is_used
        endif

        func return
      endif

    elif current_part 0 == do
      // Enable defining functions that do not return anything without the -> token
      // FUNCTION <name> <param_types> : <function_body> END
      if token_value ":" streq do
        current_part 2 + current_part =
        token_index 1 + token_index =
        token_value str.delete
        continue
      endif

      // Handle function pointer parameters
      // Example => fn[str int -> bool]
      if token_value "fn[" str.startswith do
        token_index tokens param_types token_value parse_fn_ptr_in_signature
        token_index =
        continue
      endif

      // Split token by colon to name and TokenType
      // Example => parameter_name:int
      ":" token_value str.find
      take param_colon in

      // Parse parameter's TokenType
      token_value param_colon 1 + str+
      take param_type in
      param_type cast(ptr) param_types List.append

      // Handle named parameters
      if param_colon -1 != do
        // Empty param_name
        if param_colon 0 == do
          token
          "Func '" function_name                      str.cat
          "' has parameter '"                         str.cat
          token_value                                 str.cat
          "' which has a colon but the name is empty" str.cat
          "SYNTAX_ERROR" CompilerErrorWithToken
        endif

        // Parse parameter's name
        token_value str.copy
        dup param_colon str+ str.empty
        token_value str.copy param_colon str+ 1 str+
        take
          param_type
          param_name
        in

        // Handle function pointer parameters
        // Example => fn[str int -> bool]
        if param_type "fn[" str.startswith do
          // Remove the possibly wrong parameter type
          param_types List.len 1 - param_types List.pop

          token_index tokens param_types param_type parse_fn_ptr_in_signature
          token_index =
        endif

        // Append parameter to Func's Tokens
        token Token.location
        "word"
        param_name str.copy
        Token.init
        take param_token in
        VarType.TAKE param_token Token->vartype
        param_token function_tokens cast(List) List.append

        // Add parameter to the list of Variables
        variables function_name param_token add_variable_to_list
      endif

    elif current_part 1 == do
      // Handle function pointer return types
      // Example => fn[str int -> bool]
      if token_value "fn[" str.startswith do
        token_index tokens return_types token_value parse_fn_ptr_in_signature
        token_index =
      else
        // Append word to return_types TokenType
        token_value cast(ptr) return_types List.append
      endif

    elif current_part 2 == do
      // Use Constant's value if a Constant exists named as the Token's value
      if constants token_value constant_exists do

        // Find the constant from list of Constants
        0 take constant_index in
        while constant_index constants cast(List) List.len < do
          constant_index constants cast(List) List.nth ptr.load
          take constant in

          if constant Constant.name token_value streq do
            constant Constant.value str.copy
            token Token->value
            "int" token Token->type
            break
          endif
          constant_index 1 + constant_index =
        done
      endif

      // Append the current Token to the list of tokens
      token function_tokens cast(List) List.append

    else
      "Unknown error - Function parsing failed"
      "ASSERTION_ERROR" CompilerError
    endif
    token_index 1 + token_index =
  done

  // Could not parse Func
  token
  "Could not parse function '"
  function_name               str.cat
  "'\nUnexpected end of file" str.cat
  "SYNTAX_ERROR" CompilerErrorWithToken
  NULL cast(Func)
end

// Parse function pointer as parameter or return type
// and push it to the list or types
// Params
//      type_acc:       str
//      types:          List[str]
//      tokens:         List[token]
//      token_index:    int
// Return
//      token_index: int
function parse_fn_ptr_in_signature
  type_acc:str
  types:List
  tokens:List[Token]
  token_index:int
-> int :
  // Parse empty function pointer signature
  if type_acc "fn[]" streq do
    "fn[None -> None]" cast(ptr) types List.append
    token_index return
  endif

  // Parse function with only one parameter
  if type_acc "]" str.endswith do
    " -> None]" "]" type_acc str.replace
    cast(ptr) types List.append
    token_index return
  endif

  // Append explicit None type as parameter for function with only return type
  if type_acc "->" str.endswith do
    "None ->" "->" type_acc str.replace
    type_acc =
  endif

  while token_index tokens cast(List) List.len < do
    // Get next token in the function pointer signature
    token_index 1 + token_index =
    token_index tokens cast(List) List.nth Token.load Token.value
    take signature_token_value in

    // Separate types in the signature by commas
    type_acc
    " " str.cat
    signature_token_value str.cat
    type_acc =

    // Break when parsing is finished
    if signature_token_value "]" str.endswith do
      type_acc cast(ptr) types List.append
      break
    endif
  done

  token_index
end

// Parse Classes from code
// Params
//    tokens:     List[Token]
//    functions:  List[Func]
//    constants:  List[Constant]
// Return
//    functions: List[Func]
function parse_classes
  tokens:List[Token]
  functions:List[Func]
  constants:List[Constant]
:
  0 take index in
  while index tokens cast(List) List.len < do
    // Get current word
    index tokens cast(List) List.nth ptr.load
    Token.value str.copy str.upper
    take token_upper in

    if token_upper str.copy str.upper "CLASS" streq do
      index 1 + index =
      constants functions index tokens parse_class
    endif
    index 1 + index =
  done

  // Parse the variables for each function
  functions parse_variables_for_functions
end

function parse_class
  tokens:List[Token]
  token_index:int
  functions:List[Func]
  constants:List[Constant]
:
  if token_index tokens cast(List) List.len >= do
    "Class cannot end with '"
    tokens cast(List) List.last Token.load
    Token.value str.cat
    "' token"   str.cat
    "SYNTAX_ERROR" CompilerError
  endif

  // Get Class name
  token_index tokens cast(List) List.nth ptr.load Token.value
  take class_name in
  token_index 1 + token_index =

  0 take attribute_count in
  while token_index tokens cast(List) List.len < do
    // Get current word
    token_index tokens cast(List) List.nth Token.load
    dup Token.value
    take token_value token in

    if token_value str.copy str.upper "METHOD" streq do
      // Parse all methods
      token_index 1 + token_index =
      class_name constants token_index tokens parse_function
      take class_method in

      // Add method to list of functions
      class_method functions cast(List) List.append

      // Go over the method's END keyword
      while token_index tokens cast(List) List.len < do
        token_index tokens cast(List) List.nth ptr.load
        if Token.value str.copy str.upper "END" streq do
          break
        endif
        token_index 1 + token_index =
      done

    // Class ends with ENDCLASS
    elif token_value str.copy str.upper "ENDCLASS" streq do
      // Add function called <class_name>.size
      token attribute_count class_name get_object_size_function
      functions cast(List) List.append
      return

    // Parse class attributes
    else
      functions token attribute_count class_name parse_class_attribute
      attribute_count 1 + attribute_count =
    endif
    token_index 1 + token_index =
  done

  // Could not parse class
  token
  "Could not parse class '"
  class_name                  str.cat
  "'\nUnexpected end of file" str.cat
  "SYNTAX_ERROR" CompilerErrorWithToken
end

function parse_class_attribute
  class_name:str
  attribute_count:int
  token:Token
  functions:List[Func]
:
  // Split token by colon to attribute's name and TokenType
  // Example => attribute_name:int
  token Token.value
  ":" over str.find
  take attribute_colon token_value in

  // Attribute should have a colon to separate its name and TokenType
  if
    attribute_colon -1 ==
    attribute_colon 0  ==
    ||
  do
    token
    "Invalid instance attribute '" token_value                            str.cat
    "'.\nThe attribute have a colon to separate its name and TokenType\n" str.cat
    "Example => attribute_name:int"                                       str.cat
    "SYNTAX_ERROR" CompilerErrorWithToken
  endif

  // Parse attribute's TokenType
  token_value attribute_colon 1 + str+
  take attribute_type in

  // Parse attribute's name
  token_value str.copy
  dup attribute_colon str+ str.empty
  take attribute_name in

  // Calculate attributes byte offset from object base pointer
  attribute_count int.size *
  take attribute_offset in

  // Add getter to Func list
  True token attribute_offset attribute_type attribute_name class_name
  generate_attribution_function functions cast(List) List.append

  // Add setter to Func list
  False token attribute_offset attribute_type attribute_name class_name
  generate_attribution_function functions cast(List) List.append
end

function get_object_size_function
  class_name:str
  attribute_count:int
  endclass_token:Token
-> Func :
  class_name ".size" str.cat  // function_name
  List.init cast(List[Token]) // tokens
  List.init                   // return_types
  attribute_count ptr.size *  // class_size
  take
    class_size
    return_types
    tokens
    function_name
  in

  // Insert integer Token containing class_size to Token list
  endclass_token Token.location "int" class_size itoa Token.init
  tokens cast(List) List.append

  // Signature: None -> INT
  "int" cast(ptr) return_types List.append
  return_types List.init Signature.init
  take signature in

  List.init cast(List[Variable]) tokens signature function_name Func.init
end

function generate_attribution_function
  class_name:str
  attribute_name:str
  attribute_type:str
  attribute_offset:int
  attribute_token:Token
  is_getter:bool // Getter => True, Setter => False
-> Func :
  // Func.name => Class.attribute OR Class->attribute
  class_name
  if is_getter
  do   "."
  else "->"
  endif           str.cat
  attribute_name  str.cat
  take function_name in

  // Func.Signature
  List.init
  List.init
  take param_types return_types in
  "any"           cast(ptr) param_types List.append
  attribute_type  cast(ptr)
  // Insert attribute_type to either parameter or return types
  // depending on if the function is getter or setter
  if is_getter
  do   return_types
  else param_types
  endif List.append
  return_types param_types Signature.init
  take signature in

  // Func.tokens
  is_getter attribute_token attribute_offset attribute_type attribute_name class_name get_attribute_function_tokens
  take tokens in

  // Create Func and append it to list of Funcs
  List.init cast(List[Variable]) tokens signature function_name Func.init
end

function get_attribute_function_tokens
  class_name:str
  attribute_name:str
  attribute_type:str
  attribute_offset:int
  attribute_token:Token
  is_getter:bool // Getter => True, Setter => False
-> List[Token] :
  attribute_offset itoa
  " swap cast(int) + cast(ptr) " str.cat
  if is_getter
  do   "LOAD_QWORD "  str.cat
  else "STORE_QWORD " str.cat
  endif
  List.init
  attribute_token Token.location
  dup Location.file
  take
    file_name
    location
    tokens
    code
  in

  tokens cast(List[Token]) file_name code get_tokens_from_code
  List.init cast(List[Token])
  0
  take
    index
    function_tokens
    tokens
  in
  while index tokens List.len < do
    index tokens List.nth ptr.load
    take token in

    // Fix the Location to correspond with the attribute's Token
    location token Token->location
    token function_tokens cast(List) List.append
    index 1 + index =
  done
  function_tokens
end

// Parse Variables for Funcs
// Params: List[Func]
function parse_variables_for_functions functions:List[Func] :
  functions cast(List) List.len
  0
  take index functions.len in

  // Parse Variables for each Func
  while index functions.len < do
    index functions cast(List) List.nth Func.load
    parse_function_variables
    index 1 + index = // index++
  done
end

// Parse Variables in Func
// Params: Func
// Return: None
function parse_function_variables func:Func :
  func Func.tokens
  func Func.variables
  False
  "PEEK"
  0
  take
    index
    bind_variant
    parsing_variables
    variables
    tokens
  in

  while index tokens cast(List) List.len < do
    index tokens cast(List) List.nth Token.load
    dup Token.value
    take
      token_value
      token
    in

    // Variable parsing block is started with PEEK or TAKE keyword
    if
      token_value str.copy str.upper
      dup  "PEEK" streq
      swap "TAKE" streq
      ||
    do
      True parsing_variables =
      token_value str.copy str.upper bind_variant =

    // IN keyword closes the Variable parsing block
    elif token_value str.copy str.upper "IN" streq do
      False parsing_variables =

    // Every word is considered as a Variable in the block between PEEK/TAKE and IN
    elif parsing_variables do
      if bind_variant "PEEK" streq do
        VarType.PEEK token Token->vartype
      elif bind_variant "TAKE" streq do
        VarType.TAKE token Token->vartype
      else
        token
        "Unknown VarType '" bind_variant str.cat "'\n" str.cat
        "VALUE_ERROR" CompilerErrorWithToken
      endif

      // Add Variable to Func's list of Variables
      variables func Func.name token add_variable_to_list

    // Token is a function parameter
    elif token Token.vartype 0 != do
      index 1 + index =
      continue

    // Token is an already defined Variable
    elif token_value variables List.contains_variable do
      VarType.PUSH token Token->vartype
    endif
    index 1 + index =
  done
end

// Add variable to Func's variable list
// Params
//    token: Token
//    function_name: str
//    variables: List[Variable]
function add_variable_to_list
  token:Token
  function_name:str
  variables:List[Variable]
:
  token Token.type
  token Token.value
  take token_value token_type in

  // Token is an already defined Variable
  if token_value variables List.contains_variable do
    return
  endif

  // Append the variable to the list of function's variables
  token_type token_value Variable.init
  variables cast(List) List.append
end

// Verify if 'main' function is defined (case-sensitive)
// Params
//    functions:List
// Return bool
function main_function_in_function_list functions:List[Func] -> bool :
  functions cast(List) List.len
  0
  take index functions.len in

  // Iterate over Func List
  while index functions.len < do
    index functions cast(List) List.nth ptr.load Func.name
    take function_name in

    // Return True if MAIN function is found
    if function_name "main" streq do
      True return
    endif
    index 1 + index =
  done
  False
end
