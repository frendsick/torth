// lex.torth - Lexing functions that parses Tokens from code files
include "std"
include "compiler/defs"
include "compiler/utils"
include "compiler/class/Function"
include "compiler/class/Op"
include "compiler/class/Token"
include "compiler/class/Signature"

// Transfer comparison and calculations related symbols to their text counterparts
// Params: Token match from code (STR)
// Return: Value for Token (STR)
function get_token_value str -> str :
  str.copy
  take token_match in
  if   token_match "==" streq do
    "EQ" return
  elif token_match ">=" streq do
    "GE" return
  elif token_match ">"  streq do
    "GT" return
  elif token_match "<=" streq do
    "LE" return
  elif token_match "<"  streq do
    "LT" return
  elif token_match "-"  streq do
    "MINUS" return
  elif token_match "*"  streq do
    "MUL" return
  elif token_match "!=" streq do
    "NE" return
  elif token_match "+"  streq do
    "PLUS" return
  endif
  token_match
end

const single_quote 39 end
function get_token_type str -> int :
  take token_value in
  // TODO: TokenType.KEYWORD
  // Boolean => True
  if
    token_value str.copy str.upper
    dup   "TRUE"  streq
    swap  "FALSE" streq
    ||
  do
    TokenType.BOOL return
  // Character => 'a'
  elif
    token_value str.len 3 ==
    token_value ptr char.load single_quote ==
    token_value 2 str.char_at single_quote ==
    && &&
  do
    TokenType.CHAR return
  // Integer => 1337
  elif
    token_value str.is_numeric
  do
    TokenType.INT return
  // Hexadecimal => 0x1337
  elif
    token_value ptr char.load '0' ==
    token_value 1 str.char_at 'x' ==
    &&
  do
    TokenType.INT return
  // String => "This is string\n"
  elif
    token_value ptr char.load                '"' ==
    token_value dup str.len 1 - str.char_at  '"' ==
    &&
  do
  TokenType.STR return
  // uint8 => u69
  elif
    token_value ptr char.load 'u' ==
    token_value 1 str.char_at char.is_numeric
    &&
  do
    TokenType.UINT8 return
  endif
  TokenType.WORD
end

function get_token_from_word str -> ptr :
  get_token_value dup
  get_token_type
  get_dummy_location
  swap rot Token.init
end

// Dummy memories for testing purposes
memory dummy_token_list ptr.size end
function get_tokens_function ptr -> ptr :
  drop "[TODO] Parsing Token's function is not implemented yet.\n" eputs
  dummy_token_list get_dummy_signature "test" Function.init
end

function get_op_type ptr -> int :
  Token.get_type
  take token_type in
  if token_type TokenType.BOOL == do
    OpType.PUSH_BOOL return
  elif token_type TokenType.CHAR == do
    OpType.PUSH_CHAR return
  elif token_type TokenType.INT == do
    OpType.PUSH_INT return
  elif token_type TokenType.STR == do
    OpType.PUSH_STR return
  elif token_type TokenType.UINT8 == do
    OpType.PUSH_UINT8 return
  endif
  OpType.INTRINSIC
end

// Generate Op from Token
// Params: token (PTR), id (INT)
// Return: op (PTR)
function get_op_from_token ptr int -> ptr :
  take token id in
  // Op(id=id, type=op_type, token=token, function=function)
  token get_tokens_function // function
  token                     // token
  token get_op_type         // op_type
  id                        // id
  Op.init
end

// Functions are made of four parts:
//   1 : name
//   2 : param types
//   3 : return types
//   4 : location
//  (0 : Not lexing a function)
//  FUNCTION_PART_DELIMITERS: List[str] = ["FUNCTION", "->", ":", "END"]
function get_function_part_delimiters -> ptr :
  list.init
  "FUNCTION"  ptr swap list.append
  ""          ptr swap list.append
  "->"        ptr swap list.append
  ":"         ptr swap list.append
  "END"       ptr swap list.append
end

// Get all words from code to a list
// Params
//    code: str
// Return
//    List[str]
function get_words_from_code str -> ptr :
  list.init
  "" str.copy // String buffer for word
  take
    word
    word_list
    code
  in

  0 while
    code over str.char_at
    peek current_char in
    NULL !=
  do
    if
      current_char char.is_whitespace
    do
      // If the word is empty there has been multiple whitespaces in a row
      if word str.len 0 == do
        1 +
        continue
      endif

      // Append current word to word_list
      word str.copy ptr word_list list.append
      word_list =
      word str.empty
    else
      // Append current character to word
      current_char word str.append
    endif
    1 + // index++
  done drop

  // Append the last word if the file ended with a word
  if word str.len 0 > do
    word ptr word_list list.append
    word_list =
  endif
  word_list
end

// Parse Functions from code
// Params
//    code: str
// Return
//    List[Function]
function get_functions str -> ptr :

  // Iterate over all characters in the code and get a list of words
  get_words_from_code

  // Initialize variables
  list.init                     // List[Function]
  list.init                     // List[Token]
  0                             // current_part
  get_function_part_delimiters  // FUNCTION_PART_DELIMITERS
  "" str.copy                   // String buffer for function's name
  list.init                     // return_types
  list.init                     // param_types
  0                             // index
  take
    index
    param_types
    return_types
    function_name
    FUNCTION_PART_DELIMITERS
    current_part
    tokens
    functions
    word_list
  in

  while index word_list list.len < do
    // Get current word
    index word_list list.nth str.load
    dup   get_token_from_word
    take token token_value in

    if
      token_value str.copy str.upper
      current_part FUNCTION_PART_DELIMITERS list.nth str.load
      streq
    do
      current_part 1 + 5 % current_part =

      // Append Function and reset variables when function is fully lexed
      if token_value str.copy str.upper "END" streq do

        // Append 0 token as the exit code for MAIN function
        if function_name str.copy str.upper "MAIN" streq do
          get_dummy_location TokenType.INT "0" Token.init
          tokens list.append
          tokens =
        endif

        // Function(function_name, signature, tokens)
        tokens
        return_types param_types Signature.init
        function_name Function.init
        dup Function.print  // Print the current Function

        // Append the current function to functions list
        functions list.append
        functions =

        // Reset variables
        function_name str.copy  dup str.empty   function_name =
        param_types   list.copy dup list.empty  param_types   =
        return_types  list.copy dup list.empty  return_types  =
        tokens        list.copy dup list.empty  tokens        =
      endif
      // if dup current_part != do
      //   "Token '" token_value str.cat
      //   "' is used in the wrong context when defining 'main' function\n" str.cat
      //   "FUNCTION_SIGNATURE_ERROR" CompilerError 0 exit
      //   drop ptr return
      // endif

    elif current_part 1 == do
      token_value function_name =
      current_part 1 + current_part =
      // TODO: Check for function redefinition
      // TODO: Check for Constants

    elif current_part 2 == do
      // Enable defining functions that do not return anything without the -> token
      // FUNCTION <name> <param_types> : <function_body> END
      if token_value ":" streq do
        current_part 2 + current_part =
        index 1 + index =
        continue
      endif

      // Append word to param_types if valid TokenType
      token_value Signature.type_map ptr
      param_types list.append
      param_types =
      // "[TODO] Handling -> delimiter is not implemented\n" NotImplementedError
    elif current_part 3 == do
      // Append word to return_types if valid TokenType
      token_value Signature.type_map ptr
      return_types list.append
      return_types =
    elif current_part 4 == do
      token_value get_token_from_word
      tokens list.append
      tokens =
    endif
    index 1 + index =
  done

  functions
end
